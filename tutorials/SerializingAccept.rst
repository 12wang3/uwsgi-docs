Serializing accept(), AKA Thundering Herd, AKA the Zeeg Problem
===============================================================

One of the hystorical problems in the UNIX world is the "thundering herd".

What is it ?

Take a process binding to a networking address (it could be AF_INET, AF_UNIX or whatever you want) and then forking itself:

.. code-block:: c

   int s = socket(...)
   bind(s, ...)
   listen(s, ...)
   fork()
   
after having forked itself a bunch of times, each of the process will generally start blocking on accept()

.. code-block:: c

   for(;;) {
       int client = accept(...);
       if (client < 0) continue;
       ...
   }
   
The funny problem is that on older/classic UNIX, accept() is woke up in each process blocked on it.

That means a vast amount of wasted cpu cycles (the kernel scheduler has to give control to all of the sleeping processes waiting on that socket)

This behaviour (for various reasons) is amplified when instead of processes you use threads (so, you have multiple threads blocked on accept())

The "de-facto" soluction was placing a lock before the accept() call to serialize its usage:

.. code-block:: c

   for(;;) {
       lock();
       int client = accept(...);
       unlock();
       if (client < 0) continue;
       ...
   }
   
For threads dealing with locks is generally easier, but for processes you have to fight with system-specific solutions or fallback to the venerable SysV ipc
subsystem (more on this later)

In modern times, the vast majority of UNIX systems have evolved, and now the kernel ensure (more or less) only one process/thread is woke up on a connection event.

Ok, problem solved, what we are talking abut ?

select()/poll()/kqueue()/epoll()/...
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In the pre-1.0 era, uWSGI was a lot simpler (and less interesting) than the current form. It did not have the signal framework and it was not able to listen to multiple addresses, for this reason
its loop engine was only calling accept() in each process/thread, and thundering herd (thanks to modern kernels) was not a problem.

Evolution has a price, so after a bit the standard loop engine of a uWSGI process/thread moved from:

.. code-block:: c

   for(;;) {
       int client = accept(s, ...);
       if (client < 0) continue;
       ...
   }
   
to a more "complex":

.. code-block:: c

   for(;;) {
       int interesting_fd = wait_for_fds();
       if (fd_need_accept(interesting_fd)) {
           int client = accept(interesting_fd, ...);
           if (client < 0) continue;
       }
       else if (fd_is_a_signal(interesting_fd)) {
           manage_uwsgi_signal(interesting_fd);
       }
       ...
   }
   
The problem is now the wait_for_fds() example function: it will call something like select(), poll() or the more modern epoll() and kqueue()

This kind of system calls are "monitors" for file descriptors, and they are woke up in all of the processes/threads waiting for the same file descriptor.

Before you start blaming your kernel developers, this is the right approach, as the kernel cannot knows if you are waiting for those file descriptors to call accept() or to make something funnier.

So, welcome again to the thundering herd.

Application Servers VS WebServers
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The popular, battle tested, solid, multiprocess reference webserver is for sure Apache HTTPD.

It survived decades of IT evolutions and its still one of the most important technologies powering the whole Internet.

Born as multiprocess-only, apache had to always deal with the thundering herd problem and they solved it using SysV ipc semaphores.

Even on modern Apache releases, stracing one of its process you will see something like that (it is a Linux system):

.. code-block:: c

   semop(...); // lock
   epoll_wait(...);
   accept(...);
   semop(...); // unlock
   ... // manage the request
   
the SysV semaphore protect your epoll_wait from thundering herd.

So, another problem solved, the world is a such a beatiful place... but ....

```SysV IPC is not good for application servers :(```

The definition of "application server" is pretty generic, in this case we refer to one or more process/processes generated by an unprivileged (non-root) user
binding on one ore more network address and running custom, highly undeterministic code.

Even if you had a minimal/basic knowledge on how SysV IPC works, you will know each of its component is a limited resource in the system
(and in moderns BSDs this limits are set to ridicolously low values, PostgreSQL FreeBSD users know this problem very well).

Just run 'ipcs' in your terminal to get a list of the allocated objects in your kernel. Yes, in your kernel. SysV ipc objects are persistent resources, they need
to be removed manually by the user. The same user that could allocate hundreds of those objects and fill your limited SysV IPC memory.

One of the most common problems in the apache world caused by the SysV ipc usage is the mod_rewrite leakage when you brutally kills apache instances
(yes, you should never do it, but you have not much choices if you are so brave/fool to host unreliable php apps in your webserver process)

Apache is generally a system service, managed by a consciuos sysadmin, so except few cases you can continue trusting it for more decades, even if it decides to use more SysV ipc objects :)

Your application server, sadly, is managed by different kind of users, from the most skilled one, to the one who should change job as soon as possibile to the one with the site cracked by a moron wanting to
take control of your server.

Application servers are not dangerous, users are. And application servers are run by users. The world is an ugly place.

How application server developers solved it
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Fast answer: they generally do not solve/care it

Serving static files or proxying (the main activities of a webserver) is generaly a fast, non-blocking (very deterministic under various points of view) activity. Instead a webapplication
is way slower and havier, so,  even on moderately loaded sites, the amount of sleeping processes is generally low.

On higly loaded sites you will pray for a free process, and in non-loaded sites the thundering herd problem is completely irrelevant (unless you are running
your site on a 386)

Given the relatively low number of processes you generally allocate for an application server, we can say thundering herd is a no-problem

Another approach is dynamic process spawning. If you ensure your application server has always the minimum required number of processes running
you will highly reduce the thundering herd problem.

No-problem ??? So, again, what we are talking about ?
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We are talking about "common cases", and for common cases there a plethora of valid choices (instead of uWSGI, obviously) and the vast majrity of problems
are non-existent. 

Since the beginning of the uWSGI project, being developed by an hosting company where "common cases" do not exist, we cared a lot
corner-case problems, bizarre setups and those problems the vast majority of users never need to care about.

In addition to this, uWSGI supports operational modes only common/available in general-purpose webservers like apache (i have to say apache is probably the only general purpose webserver
as it allows basically anything in its process space in a relatively safe and solid way), so lot of new problems combined with user bad-behaviours arises.

One of the most challenging devleopment phase of uWSGI was adding multithreading. Threads are powerful, but are really hard to manage right.

Threads are way cheaper than processes, so you generally allocate dozens of them for your app (remember, not used memory is wasted memory).

Dozens (or hundreds) of threads waiting for the same set of file descriptors bring us back to a thundering herd problem (unless all of your threads are constantly used)

For such a reason when you enable multiple threads in uWSGI a pthread mutex is allocated, serializing epoll()/kqueue()/poll()/select()... usage in each thread.

Another problem solved (and strange for uWSGI, without the need of an option ;)

But...

The Zeeg problem: Multiple processes with multiple threads
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

On Jun 27th, 2013 David Cramer wrote an interesting blog post (you may not agree with its conclusions, but it does not matter now, you can continue hating uWSGI safely or making funny jokes about its naming choices or the number of options)

http://justcramer.com/2013/06/27/serving-python-web-applications/

The problem David faced was a so strong thundering herd, that its response time was damaged by it (non constant performance was the main result of its tests)

Why it happened ? Was not the mutex allocated by uWSGI solving it ?

David is (was) running uWSGI with 10 process and each of them with 10 threads:

.. code-block:: sh

   uwsgi --processes 10 --threads 10
   
while the mutex protect each thread in a single process to call accept() on the same request, there is no such mechanism (or better, it is not enabled by default, see below) to protect
multiple processes from doing it, so given the number of threads (100) available for managing requests, it is unlikely that a single process
is completely blocked (read: with all of its 10 threads blocked in a request) so welcome back to the thundering herd.

How David solved it ?
^^^^^^^^^^^^^^^^^^^^^

uWSGI is a contrversial software, no shame in that. There are users fiercely hating it and others morbidly loving it, but all agree that docs could be way better ([OT] it is good when all the people agree on something, but pull requests on uwsgi-docs are embarassingly low and all from the same people.... come on, help us !!!)

David used an empirical approach, spotted its problem and decied to solve it running independent uwsgi processes bound on different sockets and configured nginx to round robin between them.



